Reviewer 3 comments, "This incorporation of quantitative probabilities is contrary to the whole approach of using qualitative probabilities." The point of this work is to evaluate how well the qualitative abstraction can be used in the real, quantitative, world.  To answer this question, we must ask "if the real world behaves like THIS then will our abstraction behave well?" where "THIS" is modeled quantitatively.

If we knew the real world's probabilities, then of course we would use them. But in this case they are not available (and as we explain, they are in principle unavailable, so simply learning them is not possible). What we show instead is that the system behaves well over a range of possible (hidden) real world configurations.  We explore the simple (unrealistic) case where all the members of the abstract classes behave identically, and then explore the more realistic case where the abstract class members (events of the same kappa rank) are more heterogeneous in their likelihood (the Beta experiments).

In the final version of the paper we will make this point clearer in the introduction.

Review 1 seems very concerned with an issue of terminology.  We have defined the term "IDS fusion" as the combination of clustering and assessment (likelihood reasoning).  The review asserts that "fusion" and "clustering" are exactly the same, and on this basis argues that we don't discuss "fusion" at all. This is not an issue where one person is right and one is wrong: the process we describe is typically referred to as "correlation" (a term we have avoided as misleading) and its input-output behavior is not consistently defined in the literature (as our related work section illustrates). We have tried to be very clear that the topic of this paper is the assessment of qualitative probabilistic reasoning as applied to combining the output of multiple sensors, and that clustering is out of scope. We described clustering only to provide context: perhaps it was a mistake to mention it at all.

Review 1's fifth point is about this same issue of terminology --- we are using "fusion" in a different sense than this reviewer.

Review 1's second and third points argue that the experimental setting and scale are insufficient for realistic evaluations of the approach for large sensor networks.  We stress that this is absolutely the first work to experimentally evaluate the performance of this kind of qualitative abstraction. At this stage, it is important to establish the behavior on small cases, where we can understand the topology, before expanding our work to larger, more complex cases, as we have proposed to do in our future work. Until we understand what sort of sensors and phenomena can be reasoned about accurately in the small, it is premature to consider complex hypotheses.

About Review 1's fourth point: P(k=1) and P(k=2) certainly can be varied as suggested.  We didn't have time to configure and run a full set of experiments during the rebuttal period, but we certainly could do so and include the results in the final version of the paper.  We ran three sets of new results with varying values for P(k=2) corresponding to the first row of that table (with P(k=1) = 0.005 and with s2a=3). As we varied p(k=2) from 0.00075, to 0.001 to 0.0025 the effect on precision was negligible, but recall went from the original 96.73% to 96.05%, 96.53%, and 94.90%. So the difference between k=1 and k=2 has much less effect than the difference between k=0 and k>0. This is not very surprising, since the difference between k=1 and k=2 is relevant only in the less common cases where there is a benign explanation for multiple reports, with no external "tie breaker."

Reviewer 1 was dissatisfied with the withheld reference. We were cautious in withholding this citation for anonymity.  However the set of authors of that paper is not identical to the set of authors of this paper, and so perhaps we were overly cautious: it is "Goldman, R. P., and Harp, S. A. 2009. Model-based intrusion assessment in Common Lisp. In Proc. Intâ€™l Lisp Conference."

We understand that the citations of related work seem unsatisfactory, but that is the state of the art.  There are not standard testbeds, etc. for IDSes, much less for systems that combine reports from multiple IDSes.  IDS correlators are rare, and as we explain they all compute slightly different things. Accordingly, the comparisons with related work are necessarily feature-based and qualitative. Our work here is intended to improve this situation.

WRT the table on page 4, the e are primitive events. So e \in \psi means that \psi is equivalent to the disjunction of the mutually exclusive events e. \omega and \phi in the subsequent sentence are conditionally independent events.
